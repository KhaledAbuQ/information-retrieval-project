{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import wikipedia\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68304,
     "status": "ok",
     "timestamp": 1762105787046,
     "user": {
      "displayName": "Mohammad Shahwan",
      "userId": "15921696030956519096"
     },
     "user_tz": -180
    },
    "id": "bTRUpJ3F50kR",
    "outputId": "372eda13-4274-4d5e-e74e-5c9b2ca749c5"
   },
   "outputs": [],
   "source": [
    "lst = [\"Artificial Intelligence\", \"Machine Learning\", \"Data Science\", \"Big Data\", \"Cloud Computing\", \"Bioinformatics\", \n",
    "       \"Data mining\", \"Cybersecurity\", \"Natural Language Processing\", \"Computer Vision\", \"Internet of Things\", \"Blockchain Technology\"]\n",
    "\n",
    "# pages = []\n",
    "# for i in lst:\n",
    "#   results = wikipedia.search(i, results = 10)\n",
    "#   for title in results:\n",
    "#     pages.append(wikipedia.page(title=title, auto_suggest=False, redirect=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(pages)):\n",
    "#     with open(f'wikipedia_objects/page_{i+1}.pkl', 'wb') as f:\n",
    "#         pickle.dump(pages[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = []\n",
    "\n",
    "# for i in range(120):\n",
    "#     with open(f'wikipedia_objects/page_{i+1}.pkl', 'rb') as f:\n",
    "#         pages.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = {'Title' : [], 'Textual Content': [], 'Link': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(pages)):\n",
    "#     dataset['Title'].append(pages[i].title)\n",
    "#     dataset['Textual Content'].append(pages[i].content)\n",
    "#     dataset['Link'].append(pages[i].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_excel(\"Information Retrieval Dataset.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"Information Retrieval Dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_topic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    words = re.findall(r'\\b[a-z]+\\b', text.lower())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      Artificial intelligence\n",
      "1              Artificial general intelligence\n",
      "2           Generative artificial intelligence\n",
      "3           History of artificial intelligence\n",
      "4                 A.I. Artificial Intelligence\n",
      "                        ...                   \n",
      "115                                      Catly\n",
      "116                            Blockchain game\n",
      "117                          Fork (blockchain)\n",
      "118    List of people in blockchain technology\n",
      "119              Cardano (blockchain platform)\n",
      "Name: Title, Length: 120, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['Textual Content'][0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_topic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in each article (Total Words, Unique Words):\n",
      "\n",
      "Words in Article Artificial intelligence: (4864, 1478)\n",
      "Words in Article Artificial general intelligence: (5056, 1493)\n",
      "Words in Article Generative artificial intelligence: (4794, 1566)\n",
      "Words in Article History of artificial intelligence: (4987, 1583)\n",
      "Words in Article A.I. Artificial Intelligence: (4052, 1394)\n",
      "Words in Article Existential risk from artificial intelligence: (4941, 1526)\n",
      "Words in Article Glossary of artificial intelligence: (4804, 1363)\n",
      "Words in Article Artificial Intelligence Act: (2393, 801)\n",
      "Words in Article Timeline of artificial intelligence: (794, 411)\n",
      "Words in Article Association for the Advancement of Artificial Intelligence: (622, 326)\n",
      "\n",
      "Total words per topic: 37307\n",
      "Total unique words per topic: 11941 \n",
      "\n",
      "Words in Article Machine learning: (4744, 1262)\n",
      "Words in Article Neural network (machine learning): (4498, 1297)\n",
      "Words in Article Attention (machine learning): (2337, 639)\n",
      "Words in Article Quantum machine learning: (4703, 1179)\n",
      "Words in Article Torch (machine learning): (596, 290)\n",
      "Words in Article Deep learning: (4756, 1382)\n",
      "Words in Article Transformer (deep learning): (3745, 916)\n",
      "Words in Article Learning: (4988, 1429)\n",
      "Words in Article Supervised learning: (2867, 711)\n",
      "Words in Article Adversarial machine learning: (3364, 957)\n",
      "\n",
      "Total words per topic: 36598\n",
      "Total unique words per topic: 10062 \n",
      "\n",
      "Words in Article Data science: (1087, 478)\n",
      "Words in Article List of data science software: (572, 306)\n",
      "Words in Article Data: (2121, 730)\n",
      "Words in Article Biomedical data science: (694, 303)\n",
      "Words in Article Data (computer science): (1948, 592)\n",
      "Words in Article Data management: (1755, 659)\n",
      "Words in Article Master in Data Science: (597, 290)\n",
      "Words in Article Data type: (3024, 801)\n",
      "Words in Article Social data science: (1990, 647)\n",
      "Words in Article Data analysis: (4459, 1268)\n",
      "\n",
      "Total words per topic: 18247\n",
      "Total unique words per topic: 6074 \n",
      "\n",
      "Words in Article Big data: (4854, 1483)\n",
      "Words in Article Data: (2121, 730)\n",
      "Words in Article Big Data Guizhou: (149, 94)\n",
      "Words in Article Data science: (1087, 478)\n",
      "Words in Article Data management: (1755, 659)\n",
      "Words in Article Big data ethics: (2345, 837)\n",
      "Words in Article Big data maturity model: (1456, 510)\n",
      "Words in Article List of big data companies: (356, 213)\n",
      "Words in Article Big Data (music project): (284, 161)\n",
      "Words in Article Data lake: (617, 300)\n",
      "\n",
      "Total words per topic: 15024\n",
      "Total unique words per topic: 5465 \n",
      "\n",
      "Words in Article Cloud computing: (4744, 1294)\n",
      "Words in Article Cloud computing security: (4915, 1266)\n",
      "Words in Article Cloud-native computing: (232, 148)\n",
      "Words in Article Cloud computing architecture: (780, 323)\n",
      "Words in Article Cloud computing issues: (4878, 1433)\n",
      "Words in Article Mobile cloud computing: (951, 393)\n",
      "Words in Article Cloud-computing comparison: (55, 31)\n",
      "Words in Article IBM Cloud: (883, 379)\n",
      "Words in Article History of cloud computing: (1174, 522)\n",
      "Words in Article Serverless computing: (1246, 567)\n",
      "\n",
      "Total words per topic: 19858\n",
      "Total unique words per topic: 6356 \n",
      "\n",
      "Words in Article Bioinformatics: (4644, 1311)\n",
      "Words in Article List of bioinformatics institutions: (106, 65)\n",
      "Words in Article International Conference on Bioinformatics: (293, 149)\n",
      "Words in Article List of bioinformatics journals: (57, 35)\n",
      "Words in Article List of open-source bioinformatics software: (89, 50)\n",
      "Words in Article Bioinformatics (journal): (231, 122)\n",
      "Words in Article Iran Bioinformatics Center: (105, 51)\n",
      "Words in Article Generative artificial intelligence: (4794, 1566)\n",
      "Words in Article List of bioinformatics companies: (132, 103)\n",
      "Words in Article Bioinformatics Research Network: (200, 102)\n",
      "\n",
      "Total words per topic: 10651\n",
      "Total unique words per topic: 3554 \n",
      "\n",
      "Words in Article Data mining: (3409, 1050)\n",
      "Words in Article Educational data mining: (2792, 825)\n",
      "Words in Article Domain driven data mining: (350, 153)\n",
      "Words in Article Data stream mining: (857, 351)\n",
      "Words in Article Evolutionary data mining: (465, 205)\n",
      "Words in Article Text mining: (2786, 984)\n",
      "Words in Article Lift (data mining): (760, 234)\n",
      "Words in Article Examples of data mining: (4088, 1335)\n",
      "Words in Article Cross-industry standard process for data mining: (655, 299)\n",
      "Words in Article Data Mining Extensions: (265, 113)\n",
      "\n",
      "Total words per topic: 16427\n",
      "Total unique words per topic: 5549 \n",
      "\n",
      "Words in Article Computer security: (4962, 1390)\n",
      "Words in Article NIST Cybersecurity Framework: (1910, 599)\n",
      "Words in Article Bitdefender: (1331, 581)\n",
      "Words in Article Cybersecurity and Infrastructure Security Agency: (1200, 593)\n",
      "Words in Article Capture the flag (cybersecurity): (846, 380)\n",
      "Words in Article Ghana: (4972, 1551)\n",
      "Words in Article International Cybersecurity Challenge: (189, 105)\n",
      "Words in Article Israeli cybersecurity industry: (477, 231)\n",
      "Words in Article Cybersecurity Law of the People's Republic of China: (1683, 618)\n",
      "Words in Article Cyber-security regulation: (4718, 1298)\n",
      "\n",
      "Total words per topic: 22288\n",
      "Total unique words per topic: 7346 \n",
      "\n",
      "Words in Article Natural language processing: (4593, 1295)\n",
      "Words in Article Natural language: (436, 218)\n",
      "Words in Article History of natural language processing: (1179, 541)\n",
      "Words in Article Quantum natural language processing: (278, 151)\n",
      "Words in Article Empirical Methods in Natural Language Processing: (252, 144)\n",
      "Words in Article Semantic decomposition (natural language processing): (531, 233)\n",
      "Words in Article Outline of natural language processing: (4730, 1247)\n",
      "Words in Article Natural-language user interface: (1582, 685)\n",
      "Words in Article Language model: (689, 327)\n",
      "Words in Article Natural language understanding: (1337, 568)\n",
      "\n",
      "Total words per topic: 15607\n",
      "Total unique words per topic: 5409 \n",
      "\n",
      "Words in Article Computer vision: (4943, 1234)\n",
      "Words in Article Computer vision syndrome: (946, 461)\n",
      "Words in Article Computer vision dazzle: (240, 145)\n",
      "Words in Article Homography (computer vision): (891, 294)\n",
      "Words in Article Feature (computer vision): (2456, 627)\n",
      "Words in Article Pose (computer vision): (458, 188)\n",
      "Words in Article Computer stereo vision: (1775, 490)\n",
      "Words in Article AlexNet: (1702, 611)\n",
      "Words in Article Graph cuts in computer vision: (1547, 525)\n",
      "Words in Article Triangulation (computer vision): (2126, 464)\n",
      "\n",
      "Total words per topic: 17084\n",
      "Total unique words per topic: 5039 \n",
      "\n",
      "Words in Article Internet of things: (4840, 1457)\n",
      "Words in Article Mechatronics: (1663, 632)\n",
      "Words in Article Industrial internet of things: (2476, 891)\n",
      "Words in Article Internet of Military Things: (3318, 1100)\n",
      "Words in Article 6G: (1062, 516)\n",
      "Words in Article Jason Johnson (entrepreneur): (418, 221)\n",
      "Words in Article IEEE Internet of Things Journal: (88, 53)\n",
      "Words in Article Internet Engineering Task Force: (2257, 784)\n",
      "Words in Article Smart system: (1029, 446)\n",
      "Words in Article Information Age: (4805, 1445)\n",
      "\n",
      "Total words per topic: 21956\n",
      "Total unique words per topic: 7545 \n",
      "\n",
      "Words in Article Blockchain: (4826, 1383)\n",
      "Words in Article Polygon (blockchain): (645, 298)\n",
      "Words in Article Privacy and blockchain: (3318, 906)\n",
      "Words in Article White paper: (1304, 525)\n",
      "Words in Article Figure (blockchain lender): (908, 357)\n",
      "Words in Article Catly: (429, 213)\n",
      "Words in Article Blockchain game: (1937, 707)\n",
      "Words in Article Fork (blockchain): (1188, 379)\n",
      "Words in Article List of people in blockchain technology: (413, 235)\n",
      "Words in Article Cardano (blockchain platform): (1403, 599)\n",
      "\n",
      "Total words per topic: 16371\n",
      "Total unique words per topic: 5602 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_words_per_topic = []\n",
    "unique_words_per_topic = []\n",
    "\n",
    "\n",
    "print(\"Words in each article (Total Words, Unique Words):\\n\")\n",
    "for j in range(0,120,10):\n",
    "    total_words = 0\n",
    "    unique_total_words = 0\n",
    "\n",
    "    for i in range(j,j+10):\n",
    "        words = clean_text(data[\"Textual Content\"].iloc[i])\n",
    "        total_words += len(words)\n",
    "        unique_words = set(words)\n",
    "        unique_total_words += len(unique_words)\n",
    "\n",
    "        print(f\"Words in Article {data['Title'].iloc[i]}: ({len(words)}, {len(unique_words)})\")\n",
    "        if article_topic.get(data['Title'].iloc[i]) is None:\n",
    "            article_topic[data['Title'].iloc[i]] = [lst[j//10]]\n",
    "        else:\n",
    "            article_topic[data['Title'].iloc[i]].append(lst[j//10])\n",
    "\n",
    "    \n",
    "\n",
    "    total_words_per_topic.append(total_words)\n",
    "    unique_words_per_topic.append(unique_total_words)\n",
    "\n",
    "    print(\"\\nTotal words per topic:\", total_words)\n",
    "    print(\"Total unique words per topic:\", unique_total_words, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique articles: 116\n",
      "\n",
      "Articles associated with multiple topics:\n",
      "\n",
      "Article: Generative artificial intelligence\n",
      "Topics: ['Artificial Intelligence', 'Bioinformatics']\n",
      "\n",
      "Article: Data science\n",
      "Topics: ['Data Science', 'Big Data']\n",
      "\n",
      "Article: Data\n",
      "Topics: ['Data Science', 'Big Data']\n",
      "\n",
      "Article: Data management\n",
      "Topics: ['Data Science', 'Big Data']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique articles:\", len(article_topic))\n",
    "\n",
    "print(\"\\nArticles associated with multiple topics:\\n\")\n",
    "for i in article_topic:\n",
    "    if len(article_topic[i]) > 1:\n",
    "        print(f\"Article: {i}\\nTopics: {article_topic[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words per topic: [37307, 36598, 18247, 15024, 19858, 10651, 16427, 22288, 15607, 17084, 21956, 16371]\n",
      "Total unique words per topic: [11941, 10062, 6074, 5465, 6356, 3554, 5549, 7346, 5409, 5039, 7545, 5602]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words per topic:\", total_words_per_topic)\n",
    "print(\"Total unique words per topic:\", unique_words_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of unique words in topic 1: 32.01%\n",
      "Percentage of unique words in topic 2: 27.49%\n",
      "Percentage of unique words in topic 3: 33.29%\n",
      "Percentage of unique words in topic 4: 36.38%\n",
      "Percentage of unique words in topic 5: 32.01%\n",
      "Percentage of unique words in topic 6: 33.37%\n",
      "Percentage of unique words in topic 7: 33.78%\n",
      "Percentage of unique words in topic 8: 32.96%\n",
      "Percentage of unique words in topic 9: 34.66%\n",
      "Percentage of unique words in topic 10: 29.5%\n",
      "Percentage of unique words in topic 11: 34.36%\n",
      "Percentage of unique words in topic 12: 34.22%\n"
     ]
    }
   ],
   "source": [
    "percentage_unique_words_per_topic = []\n",
    "\n",
    "for i in range(len(total_words_per_topic)):\n",
    "    percentage = (unique_words_per_topic[i] / total_words_per_topic[i]) * 100\n",
    "    percentage_unique_words_per_topic.append(percentage)\n",
    "    print(f\"Percentage of unique words in topic {i+1}: {round(percentage, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in Article 1: (4864, 1478)\n",
      "Words in Article 2: (5056, 1493)\n",
      "Words in Article 3: (4794, 1566)\n",
      "Words in Article 4: (4987, 1583)\n",
      "Words in Article 5: (4052, 1394)\n",
      "Words in Article 6: (4941, 1526)\n",
      "Words in Article 7: (4804, 1363)\n",
      "Words in Article 8: (2393, 801)\n",
      "Words in Article 9: (794, 411)\n",
      "Words in Article 10: (622, 326)\n",
      "Words in Article 11: (4744, 1262)\n",
      "Words in Article 12: (4498, 1297)\n",
      "Words in Article 13: (2337, 639)\n",
      "Words in Article 14: (4703, 1179)\n",
      "Words in Article 15: (596, 290)\n",
      "Words in Article 16: (4756, 1382)\n",
      "Words in Article 17: (3745, 916)\n",
      "Words in Article 18: (4988, 1429)\n",
      "Words in Article 19: (2867, 711)\n",
      "Words in Article 20: (3364, 957)\n",
      "Words in Article 21: (1087, 478)\n",
      "Words in Article 22: (572, 306)\n",
      "Words in Article 23: (2121, 730)\n",
      "Words in Article 24: (694, 303)\n",
      "Words in Article 25: (1948, 592)\n",
      "Words in Article 26: (1755, 659)\n",
      "Words in Article 27: (597, 290)\n",
      "Words in Article 28: (3024, 801)\n",
      "Words in Article 29: (1990, 647)\n",
      "Words in Article 30: (4459, 1268)\n",
      "Words in Article 31: (4854, 1483)\n",
      "Words in Article 32: (2121, 730)\n",
      "Words in Article 33: (149, 94)\n",
      "Words in Article 34: (1087, 478)\n",
      "Words in Article 35: (1755, 659)\n",
      "Words in Article 36: (2345, 837)\n",
      "Words in Article 37: (1456, 510)\n",
      "Words in Article 38: (356, 213)\n",
      "Words in Article 39: (284, 161)\n",
      "Words in Article 40: (617, 300)\n",
      "Words in Article 41: (4744, 1294)\n",
      "Words in Article 42: (4915, 1266)\n",
      "Words in Article 43: (232, 148)\n",
      "Words in Article 44: (780, 323)\n",
      "Words in Article 45: (4878, 1433)\n",
      "Words in Article 46: (951, 393)\n",
      "Words in Article 47: (55, 31)\n",
      "Words in Article 48: (883, 379)\n",
      "Words in Article 49: (1174, 522)\n",
      "Words in Article 50: (1246, 567)\n",
      "Words in Article 51: (4644, 1311)\n",
      "Words in Article 52: (106, 65)\n",
      "Words in Article 53: (293, 149)\n",
      "Words in Article 54: (57, 35)\n",
      "Words in Article 55: (89, 50)\n",
      "Words in Article 56: (231, 122)\n",
      "Words in Article 57: (105, 51)\n",
      "Words in Article 58: (4794, 1566)\n",
      "Words in Article 59: (132, 103)\n",
      "Words in Article 60: (200, 102)\n",
      "Words in Article 61: (3409, 1050)\n",
      "Words in Article 62: (2792, 825)\n",
      "Words in Article 63: (350, 153)\n",
      "Words in Article 64: (857, 351)\n",
      "Words in Article 65: (465, 205)\n",
      "Words in Article 66: (2786, 984)\n",
      "Words in Article 67: (760, 234)\n",
      "Words in Article 68: (4088, 1335)\n",
      "Words in Article 69: (655, 299)\n",
      "Words in Article 70: (265, 113)\n",
      "Words in Article 71: (4962, 1390)\n",
      "Words in Article 72: (1910, 599)\n",
      "Words in Article 73: (1331, 581)\n",
      "Words in Article 74: (1200, 593)\n",
      "Words in Article 75: (846, 380)\n",
      "Words in Article 76: (4972, 1551)\n",
      "Words in Article 77: (189, 105)\n",
      "Words in Article 78: (477, 231)\n",
      "Words in Article 79: (1683, 618)\n",
      "Words in Article 80: (4718, 1298)\n",
      "Words in Article 81: (4593, 1295)\n",
      "Words in Article 82: (436, 218)\n",
      "Words in Article 83: (1179, 541)\n",
      "Words in Article 84: (278, 151)\n",
      "Words in Article 85: (252, 144)\n",
      "Words in Article 86: (531, 233)\n",
      "Words in Article 87: (4730, 1247)\n",
      "Words in Article 88: (1582, 685)\n",
      "Words in Article 89: (689, 327)\n",
      "Words in Article 90: (1337, 568)\n",
      "Words in Article 91: (4943, 1234)\n",
      "Words in Article 92: (946, 461)\n",
      "Words in Article 93: (240, 145)\n",
      "Words in Article 94: (891, 294)\n",
      "Words in Article 95: (2456, 627)\n",
      "Words in Article 96: (458, 188)\n",
      "Words in Article 97: (1775, 490)\n",
      "Words in Article 98: (1702, 611)\n",
      "Words in Article 99: (1547, 525)\n",
      "Words in Article 100: (2126, 464)\n",
      "Words in Article 101: (4840, 1457)\n",
      "Words in Article 102: (1663, 632)\n",
      "Words in Article 103: (2476, 891)\n",
      "Words in Article 104: (3318, 1100)\n",
      "Words in Article 105: (1062, 516)\n",
      "Words in Article 106: (418, 221)\n",
      "Words in Article 107: (88, 53)\n",
      "Words in Article 108: (2257, 784)\n",
      "Words in Article 109: (1029, 446)\n",
      "Words in Article 110: (4805, 1445)\n",
      "Words in Article 111: (4826, 1383)\n",
      "Words in Article 112: (645, 298)\n",
      "Words in Article 113: (3318, 906)\n",
      "Words in Article 114: (1304, 525)\n",
      "Words in Article 115: (908, 357)\n",
      "Words in Article 116: (429, 213)\n",
      "Words in Article 117: (1937, 707)\n",
      "Words in Article 118: (1188, 379)\n",
      "Words in Article 119: (413, 235)\n",
      "Words in Article 120: (1403, 599)\n"
     ]
    }
   ],
   "source": [
    "for j in range(0,120,10):\n",
    "    total_words = 0\n",
    "    unique_total_words = 0\n",
    "\n",
    "    for i in range(j,j+10):\n",
    "        words = clean_text(data[\"Textual Content\"][i])\n",
    "        total_words += len(words)\n",
    "        unique_words = set(words)\n",
    "        unique_total_words += len(unique_words)\n",
    "\n",
    "        print(f\"Words in Article {i+1}: ({len(words)}, {len(unique_words)})\")\n",
    "    total_words_per_topic.append(total_words)\n",
    "    unique_words_per_topic.append(unique_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text_stopword_filtered = []\n",
    "for j in range(0,120,10):\n",
    "    for i in data[\"Textual Content\"][j:j+10]:\n",
    "        doc = nlp(i)\n",
    "        filtered_words = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "        text_stopword_filtered.append(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) 21387\n",
      "10) 20690\n",
      "20) 10820\n",
      "30) 8997\n",
      "40) 11699\n",
      "50) 6579\n",
      "60) 9770\n",
      "70) 13042\n",
      "80) 9111\n",
      "90) 9307\n",
      "100) 12782\n",
      "110) 9204\n"
     ]
    }
   ],
   "source": [
    "without_stopwords = []\n",
    "for j in range(0,120,10):\n",
    "    xi = sum(len(words) for words in text_stopword_filtered[j:j+10])\n",
    "    without_stopwords.append(xi)\n",
    "    print(f\"{j}) {xi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words per topic: [37307, 36598, 18247, 15024, 19858, 10651, 16427, 22288, 15607, 17084, 21956, 16371, 37307, 36598, 18247, 15024, 19858, 10651, 16427, 22288, 15607, 17084, 21956, 16371]\n",
      "Without stopwords: [21387, 20690, 10820, 8997, 11699, 6579, 9770, 13042, 9111, 9307, 12782, 9204]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words per topic:\", total_words_per_topic)\n",
    "print(\"Without stopwords:\", without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Topic': [], 'Number of Articles': [], 'Total Words': [], 'Unique Words': [], 'Unique Words Percentage': [], 'Percentage Stop Words': []}\n",
    "# using list without_stopwords to calculate percentage of stop words per topic\n",
    "for i in range(len(lst)):\n",
    "    d['Topic'].append(lst[i])\n",
    "    d['Number of Articles'].append(10)\n",
    "    d['Total Words'].append(total_words_per_topic[i])\n",
    "    d['Unique Words'].append(unique_words_per_topic[i])\n",
    "    # percentage to two deciamal places\n",
    "    d['Unique Words Percentage'].append(round((d['Unique Words'][i]/d['Total Words'][i])*100, 2))\n",
    "    d['Percentage Stop Words'].append(round((d['Total Words'][i] - without_stopwords[i])/d['Total Words'][i]*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d).to_excel(\"Dataset Summary.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNVzsem1ZM6pzP/LsomzTAB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "retrieval-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
